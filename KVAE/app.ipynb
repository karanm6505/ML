{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\adity\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageTk\n",
    "import tempfile\n",
    "from tkinter import *\n",
    "from tkinter import Tk, Checkbutton, IntVar\n",
    "\n",
    "# Define SimpleUNet model\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        self.num_classes = num_classes  # Ensure num_classes is an attribute\n",
    "\n",
    "        self.enc1 = self.conv_block(1 + num_classes, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2, padding=0)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2, padding=0)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        # Convert label to one-hot encoding\n",
    "        label_onehot = F.one_hot(label, num_classes=self.num_classes).float()\n",
    "        label_onehot = label_onehot.unsqueeze(-1).unsqueeze(-1)\n",
    "        label_onehot = label_onehot.expand(-1, -1, image.size(2), image.size(3))\n",
    "\n",
    "        x = torch.cat((image, label_onehot), dim=1)\n",
    "\n",
    "        # Encoder path\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc3, 2))\n",
    "        dec3 = self.upconv3(bottleneck)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.dec3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.dec2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.dec1(dec1)\n",
    "\n",
    "        # Output layer\n",
    "        output = self.out_conv(dec1)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "class SimpleUNet32(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super(SimpleUNet32, self).__init__()\n",
    "        self.num_classes = num_classes  # Ensure num_classes is an attribute\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(1 + num_classes, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2,padding=0)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2,padding=0)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                # init.xavier_uniform_(m.weight)\n",
    "\n",
    "                init.xavier_uniform(m.weight)\n",
    "                # init.xavier_uniform(m.bias)\n",
    "\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        # Convert label to one-hot encoding\n",
    "        label_onehot = F.one_hot(label, num_classes=self.num_classes).float()\n",
    "        label_onehot = label_onehot.unsqueeze(-1).unsqueeze(-1)\n",
    "        label_onehot = label_onehot.expand(-1, -1, image.size(2), image.size(3))\n",
    "\n",
    "        # Concatenate image and label along the channel dimension\n",
    "        x = torch.cat((image, label_onehot), dim=1)\n",
    "\n",
    "        # Encoder path\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(F.max_pool2d(enc1, 2))\n",
    "        enc3 = self.enc3(F.max_pool2d(enc2, 2))\n",
    "        enc4 = self.enc4(F.max_pool2d(enc3, 2))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))\n",
    "    \n",
    "        # print(bottleneck.shape)\n",
    "        # Decoder path with skip connections\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        # dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        # dec4 = self.dec4(dec4)\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        # dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        # dec3 = self.dec3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        # dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        # dec2 = self.dec2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.dec1(dec1)\n",
    "\n",
    "        # Output layer\n",
    "        output = self.out_conv(dec1)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_24092\\1709433868.py:38: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk, ImageGrab\n",
    "import torch\n",
    "from PIL import ImageOps\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "class Paint(object):\n",
    "    def __init__(self):\n",
    "        self.root = Tk()\n",
    "\n",
    "        self.model = SimpleUNet32(num_classes=50)\n",
    "        self.model.load_state_dict(torch.load('Unet32x48/model4.pth'))\n",
    "        \n",
    "        # self.model = SimpleUNet(num_classes=50)\n",
    "        # self.model.load_state_dict(torch.load('Unet/model5.pth'))\n",
    "        self.model.eval()\n",
    "\n",
    "        self.options = [\"ಅ\", \"ಆ\", \"ಇ\", \"ಈ\", \"ಉ\", \"ಊ\", \"ಋ\", \"ಎ\", \"ಏ\", \"ಐ\", \"ಒ\", \"ಓ\", \"ಔ\", \"ಅಂ\", \"ಅಃ\", 'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', 'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', 'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', 'ಯ', 'ರ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ']\n",
    "        self.clicked = StringVar()\n",
    "        self.clicked.set(self.options[0])  # Setting the default value\n",
    "\n",
    "        drop = OptionMenu(self.root, self.clicked, *self.options)\n",
    "        drop.grid(row=0, column=4)\n",
    "\n",
    "        self.label = Label(self.root, text=\" \")\n",
    "        self.label.grid(row=0, column=3)\n",
    "\n",
    "        self.button = Button(self.root, text=\"Regenerate\", command=self.regenerate)\n",
    "        self.button.grid(row=1, column=6)\n",
    "\n",
    "        self.eraser_button = Button(self.root, text='eraser', command=self.use_eraser)\n",
    "        self.eraser_button.grid(row=0, column=0)\n",
    "\n",
    "        self.reset_button = Button(self.root, text='reset', command=self.reset_screen)\n",
    "        self.reset_button.grid(row=0, column=1)\n",
    "\n",
    "        self.choose_size_button = Scale(self.root,from_=22, to=48, orient=HORIZONTAL)\n",
    "        self.choose_size_button.set(32)\n",
    "        self.choose_size_button.grid(row=0, column=2)\n",
    "\n",
    "        self.c = Canvas(self.root, bg='white', width=640, height=480)\n",
    "        self.c.grid(row=1, columnspan=5)\n",
    "\n",
    "        self.threshold_checkbox_var = IntVar()\n",
    "        self.threshold_checkbox = Checkbutton(self.root, text=\"Threshold\",variable=self.threshold_checkbox_var,command=self.threshold_function)\n",
    "        self.threshold_checkbox.select()\n",
    "        self.threshold_checkbox.grid(row=0, column=7)\n",
    "\n",
    "        self.choose_threshold_button = Scale(self.root, length=90,from_=5, to=240, orient=HORIZONTAL ,command=self.threshold_function)\n",
    "        self.choose_threshold_button.set(128)\n",
    "        self.choose_threshold_button.grid(row=0, column=8)\n",
    "\n",
    "\n",
    "        self.choose_Noise_button = Scale(self.root,length=90,from_=0, to=100, orient=HORIZONTAL ,command=self.regenerate)\n",
    "        self.choose_Noise_button.set(0)\n",
    "        self.choose_Noise_button.grid(row=0, column=10)\n",
    "\n",
    "\n",
    "        self.c2 = Canvas(self.root, bg='white', width=640, height=480)\n",
    "        self.c2.grid(row=1, column=7, columnspan=5)\n",
    "\n",
    "        self.setup()\n",
    "        self.root.mainloop()\n",
    "        # self.reset_screen()\n",
    "    def setup(self):\n",
    "        self.old_x = None\n",
    "        self.old_y = None\n",
    "        self.line_width = self.choose_size_button.get()\n",
    "        self.eraser_on = False\n",
    "        self.c.bind('<B1-Motion>', self.paint)\n",
    "        self.c.bind('<ButtonRelease-1>', self.reset)\n",
    "\n",
    "    def preprocess_image(self, pil_image, image_dim):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),  # Convert image to grayscale\n",
    "            transforms.Resize(image_dim),  # Resize to the desired dimensions\n",
    "            transforms.ToTensor(),  # Convert image to tensor\n",
    "            transforms.Lambda(lambda img: 1 - img),  # Apply binary transformation\n",
    "            transforms.RandomAffine(degrees=0, translate=(0, 0.1), scale=(0.95, 0.96)),  # Normalize the image\n",
    "        ])\n",
    "        image = transform(pil_image)\n",
    "        image = image.unsqueeze(0)  # Add batch dimension\n",
    "        return image\n",
    "\n",
    "\n",
    "    def threshold_function(self,event=None):\n",
    "        if event:\n",
    "            self.threshold_checkbox.select()\n",
    "        try:\n",
    "            self.set_output_canvas()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def regenerate(self,event=None):\n",
    "        # Update label text\n",
    "        # self.label.config(text=\"id:\" + str(self.options.index(self.clicked.get())))\n",
    "        img_size=(32,48)\n",
    "        # img_size=(24,32)\n",
    "\n",
    "        # Get the canvas bounding box\n",
    "        x = self.root.winfo_rootx() + self.c.winfo_x()\n",
    "        y = self.root.winfo_rooty() + self.c.winfo_y()\n",
    "        x1 = x + self.c.winfo_width()\n",
    "        y1 = y + self.c.winfo_height()\n",
    "\n",
    "        # Capture the canvas as a PIL image\n",
    "        canvas_image = ImageGrab.grab().crop((x, y, x1, y1))\n",
    "        canvas_image = ImageOps.grayscale(canvas_image)\n",
    "\n",
    "        canvas_image = canvas_image.resize(img_size,Image.LANCZOS)\n",
    "        # Preprocess the captured image\n",
    "        processed_image = self.preprocess_image(canvas_image, img_size)\n",
    "        input_image= processed_image\n",
    "        input_image = processed_image + torch.randn(processed_image.size())*self.choose_Noise_button.get()/100\n",
    "        input_image = input_image.clamp(0, 1)\n",
    "\n",
    "        input_label = torch.tensor([self.options.index(self.clicked.get())])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_image, input_label)\n",
    "        # with torch.no_grad():\n",
    "        #     output = self.model(output, input_label)\n",
    "        # # with torch.no_grad():\n",
    "        #     output = self.model(output, input_label)\n",
    "        # # with torch.no_grad():\n",
    "        #     output = self.model(output, input_label)\n",
    "\n",
    "        output_image_np = output.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "        output_image_pil = Image.fromarray((output_image_np * 255).astype('uint8'))\n",
    "        # Binarize the output image\n",
    "        output_image_pil = output_image_pil.resize((640, 480), Image.LANCZOS)\n",
    "\n",
    "        self.output_image_before_threshold = output_image_pil\n",
    "        self.set_output_canvas()\n",
    "\n",
    "    def set_output_canvas(self):\n",
    "        output_image_pil=self.output_image_before_threshold\n",
    "        if self.threshold_checkbox_var.get() == 1:\n",
    "            threshold = self.choose_threshold_button.get()\n",
    "            output_image_pil = output_image_pil.point(lambda x: 0 if x < threshold else 255)\n",
    "        # Convert resized PIL image to NumPy array\n",
    "        output_image_resized_np = np.array(output_image_pil) / 255.0\n",
    "\n",
    "        # Compute the maximum pixel values between canvas and output images\n",
    "        max_image_np = 1-output_image_resized_np  # Ensure values are in the range [0, 1]\n",
    "        # Convert the maximum image to a PIL image\n",
    "        max_image_pil = Image.fromarray((max_image_np * 255).astype('uint8'))\n",
    "\n",
    "        # Display the image on the canvas\n",
    "\n",
    "        self.output_image = ImageTk.PhotoImage(max_image_pil)\n",
    "        self.c2.create_image(0, 0, image=self.output_image, anchor='nw')\n",
    "\n",
    "\n",
    "    def use_eraser(self):\n",
    "        if not self.eraser_on:\n",
    "            self.eraser_button.config(relief=SUNKEN)\n",
    "            self.eraser_on = True\n",
    "        else:\n",
    "            self.eraser_button.config(relief=RAISED)\n",
    "            self.eraser_on = False\n",
    "\n",
    "    def paint(self, event):\n",
    "        self.line_width = self.choose_size_button.get()\n",
    "        paint_color = 'white' if self.eraser_on else 'black'\n",
    "        if self.old_x and self.old_y:\n",
    "            self.c.create_line(self.old_x, self.old_y, event.x, event.y, width=self.line_width, fill=paint_color, capstyle=ROUND, smooth=True, splinesteps=36)\n",
    "        self.old_x = event.x\n",
    "        self.old_y = event.y\n",
    "\n",
    "    def reset(self, event):\n",
    "        self.old_x, self.old_y = None, None\n",
    "    def reset_screen(self):\n",
    "        self.c.delete(\"all\")\n",
    "        self.c2.delete(\"all\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Paint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# del Paint\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     # Empty the CUDA cache\n",
    "#     torch.cuda.empty_cache()\n",
    "# else:\n",
    "#     # Print a message indicating that CUDA is not available\n",
    "#     print(\"CUDA is not available.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
